FROM nvcr.io/nvidia/cuda:12.4.1-devel-ubuntu22.04 AS base

# For tzdata
ENV DEBIAN_FRONTEND="noninteractive" TZ="Etc/UTC"

RUN sed -i "s/archive/us.archive/g" /etc/apt/sources.list

# Install Python 3.11 and set it AS default
RUN apt-get update && \
    apt-get install -y software-properties-common && \
    add-apt-repository ppa:deadsnakes/ppa && \
    apt-get update && \
    apt-get install -y python3.11 python3.11-venv python3-pip python3.11-dev && \
    ln -sf /usr/bin/python3.11 /usr/bin/python3 && \
    python3 --version

# Install poetry
RUN pip install pipx
RUN python3 -m pipx ensurepath
RUN pipx install poetry
ENV PATH="/root/.local/bin:$PATH"
ENV PATH=".venv/bin/:$PATH"

# Dependencies to build llama-cpp
RUN apt update && apt install -y \
  libopenblas-dev\
  ninja-build\
  build-essential\
  pkg-config\
  wget\
  gcc

# https://python-poetry.org/docs/configuration/#virtualenvsin-project
ENV POETRY_VIRTUALENVS_IN_PROJECT=true

#########################
FROM base AS dependencies
#########################

ARG LLAMA_CPP_PYTHON_VERSION=0.2.63
ARG CMAKE_ARGS='-DLLAMA_CUDA=on -DLLAMA_CUDA_FORCE_MMQ=on'

WORKDIR /home/worker/app
COPY pyproject.toml ./

RUN poetry config installer.max-workers 4
RUN poetry install --with local
RUN poetry install --with ui

# Enable GPU support
# Use this if your GPU performs better at FP32 than FP16
# CMAKE_ARGS="-DLLAMA_CUDA=on -DLLAMA_CUDA_FORCE_MMQ=on"
RUN rm -f CMakeCache.txt && CMAKE_ARGS=${CMAKE_ARGS} FORCE_CMAKE=1 poetry run pip install --upgrade --force-reinstall --no-cache-dir llama-cpp-python==${LLAMA_CPP_PYTHON_VERSION}

################
FROM nvcr.io/nvidia/cuda:12.4.1-runtime-ubuntu22.04 AS app
################
ARG LLAMA_CPP_PYTHON_VERSION=0.2.63
ARG CMAKE_ARGS='-DLLAMA_CUDA=on -DLLAMA_CUDA_FORCE_MMQ=on'

ENV DEBIAN_FRONTEND="noninteractive" TZ="Etc/UTC"
RUN sed -i "s/archive/us.archive/g" /etc/apt/sources.list

# Install Python 3.11 and set it AS default
# This is let us know at runtime how llama_cpp_python was compiled
# Make sure it is the same as the dependencies stage
ENV CMAKE_ARGS=${CMAKE_ARGS}
ENV LLAMA_CPP_PYTHON_VERSION=${LLAMA_CPP_PYTHON_VERSION}
RUN apt-get update && \
    apt-get install -y software-properties-common && \
    add-apt-repository ppa:deadsnakes/ppa && \
    apt-get update && \
    apt-get install -y python3.11 python3.11-venv python3-pip python3.11-dev && \
    ln -sf /usr/bin/python3.11 /usr/bin/python3 && \
    python3 --version

# Install poetry
RUN pip install pipx
RUN python3 -m pipx ensurepath
ENV PATH="/root/.local/bin:$PATH"
ENV PATH=".venv/bin/:$PATH"

ENV PYTHONUNBUFFERED=1
ENV PORT=8080
EXPOSE 8080

# Prepare a non-root user
RUN adduser worker
WORKDIR /home/worker/app

RUN mkdir -p local_data; chown -R worker local_data
RUN mkdir -p models; chown -R worker models
COPY --chown=worker --from=dependencies /home/worker/app/.venv/ .venv
COPY --chown=worker private_gpt/ private_gpt
COPY --chown=worker fern/ fern
COPY --chown=worker *.yaml *.md ./
COPY --chown=worker scripts/ scripts
COPY --chown=worker pyproject.toml ./

# Copy the entry point script into the container and make it executable
# TODO: factorize entrypoint.sh from lukaboljevic/privateGPT
# 1. setup
# 2. ingest
# 3. run
#COPY --chown=worker entrypoint.sh /entrypoint.sh
#RUN chmod +x /entrypoint.sh

ENV PYTHONPATH="$PYTHONPATH:/home/worker/app/private_gpt/"

USER worker
ENTRYPOINT ["/home/worker/app/.venv/bin/python", "-m" , "private_gpt"]
